# Spark configuration file (spark-defaults.conf)
# LINK: https://spark.apache.org/docs/latest/api/scala/org/apache/spark/SparkConf.html

# General Spark Configuration
spark.app.name                                          DataBricks
spark.master                                            spark://node-master:7077
spark.driver.memory                                     2g
spark.executor.memory                                   4g
spark.executor.cores                                    4
spark.cores.max                                         4
spark.executor.instances                                2
spark.sql.shuffle.partitions                            200
spark.serializer                                        org.apache.spark.serializer.KryoSerializer
spark.rdd.compress                                      true
spark.default.parallelism                               100

# Delta Lake Configuration
spark.sql.extensions                                    io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog                         org.apache.spark.sql.delta.catalog.DeltaCatalog
# spark.databricks.delta.retentionDurationCheck.enabled   false

# Photon Configuration
# spark.databricks.photon.enabled                       true
# spark.databricks.photon.loadNative                    true

# S3/MinIO Configuration
spark.hadoop.fs.s3a.endpoint                            http://object-storage:9000
spark.hadoop.fs.s3a.access.key                          admin*12345
spark.hadoop.fs.s3a.secret.key                          psswrd*12345
spark.hadoop.fs.s3a.path.style.access                   true
spark.hadoop.fs.s3a.impl                                org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled              false

# History Server
# spark.eventLog.enabled                                true
# spark.eventLog.dir                                    s3a://spark-events/
# spark.history.fs.logDirectory                         s3a://spark-events/





# DEFAULT: Logging and event history
# spark.eventLog.enabled           true
# spark.eventLog.dir               file:/tmp/spark-events
# spark.history.fs.logDirectory    file:/tmp/spark-events

# # Dynamic allocation
# spark.dynamicAllocation.enabled  true
# spark.dynamicAllocation.initialExecutors 2
# spark.dynamicAllocation.minExecutors     1
# spark.dynamicAllocation.maxExecutors     10

# # Network timeout settings
# spark.network.timeout            600s
# spark.executor.heartbeatInterval 100s

# # YARN settings (if applicable)
# spark.yarn.am.memory             1g
# spark.yarn.am.cores              1

# # Shuffle and memory management
# spark.shuffle.service.enabled    true
# spark.memory.fraction            0.6
# spark.memory.storageFraction     0.5
# spark.memory.offHeap.enabled     false
# spark.memory.offHeap.size        512m

# # Advanced settings
# spark.sql.autoBroadcastJoinThreshold 10MB
# spark.sql.files.maxPartitionBytes    128MB
# spark.sql.files.openCostInBytes      4MB
# spark.sql.broadcastTimeout           300

# # Security settings
# spark.authenticate                 true
# spark.authenticate.secret           some_secret
# spark.network.crypto.enabled        true
# spark.ssl.enabled                   false
# spark.ssl.protocol                  TLS
# spark.ssl.keyStore                  /path/to/keystore
# spark.ssl.keyStorePassword          some_password
# spark.ssl.keyPassword               some_password
# spark.ssl.trustStore                /path/to/truststore
# spark.ssl.trustStorePassword        some_password
