{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086bc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spark_init import create_spark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12804804-38fc-4dbf-b5f2-71bb9f9af207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Local Databricks Stack\n",
    "# This script demonstrates the integration of all components in our local Databricks-like environment.\n",
    "from os import environ\n",
    "\n",
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "# import mlflow\n",
    "# import mlflow.spark\n",
    "from delta import *\n",
    "# import pandas as pd\n",
    "# import polars as pl\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bebfb41-66d1-4f35-a484-439df04730da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2991f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session()\n",
    "\n",
    "print(\"Spark session created successfully!\")\n",
    "print(f\"Spark version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab11e3-3c25-4ace-9b0a-92c0c837d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Delta Lake\n",
    "# Create sample data\n",
    "data = [(1, \"test1\"), (2, \"test2\"), (3, \"test3\")]\n",
    "df = spark.createDataFrame(data, [\"id\", \"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a98be4-9958-4192-a88c-1b31f10b9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to Delta Lake format in MinIO\n",
    "df.write.format(\"parquet\").mode(\"overwrite\").save(\"/home/jovyan/workspace/test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c458e1ae-d52a-40c8-b013-4e987fadd8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from Delta Lake\n",
    "df_read = spark.read.format(\"parquet\").load(\"/home/jovyan/workspace/test2\")\n",
    "df_read.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41672eb-e8da-4ce5-83ad-b697c767f829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595197c-b5bf-4281-8e87-731515e0a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa11b9e-a2ee-489a-add5-5e59e4695ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test Delta Lake\n",
    "# # Create sample data\n",
    "# data = [(1, \"test1\"), (2, \"test2\"), (3, \"test3\")]\n",
    "# df = spark.createDataFrame(data, [\"id\", \"value\"])\n",
    "\n",
    "# # Write to Delta Lake format in MinIO\n",
    "# df.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://delta/test-table\")\n",
    "\n",
    "# # Read from Delta Lake\n",
    "# df_read = spark.read.format(\"delta\").load(\"s3a://delta/test-table\")\n",
    "# df_read.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdcdcba-94b5-4f3c-9d1a-973c6165f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MLflow integration\n",
    "# Create sample ML model\n",
    "mlflow.set_experiment(\"test-experiment\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Generate sample data\n",
    "    X = np.random.rand(100, 4)\n",
    "    y = np.random.rand(100)\n",
    "    \n",
    "    # Train a model\n",
    "    model = RandomForestRegressor(n_estimators=100)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Log parameters and model\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.sklearn.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd596e-59fe-4858-9c94-0116efc7dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SQL Magic\n",
    "query = \"SELECT * FROM `/home/jovyan/workspace/test1`\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae42cf7-028c-4d87-b460-d3e4a1d99541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SQL Magic\n",
    "query = \"SELECT * FROM delta.`s3a://delta/test-table`\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dcc14e-286b-44cf-93f8-e9384af0e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Polars integration\n",
    "# Convert Spark DataFrame to Polars\n",
    "pandas_df = df_read.toPandas()\n",
    "polars_df = pl.from_pandas(pandas_df)\n",
    "print(\"Polars DataFrame:\")\n",
    "print(polars_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c530145-df16-4a8a-ac2e-b920543f7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9182a9e-2495-4307-b16b-6f5bec017919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
